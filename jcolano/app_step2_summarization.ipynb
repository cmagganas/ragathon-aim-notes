{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# INITIALIZE GPT 4\n",
    "api_key = \"\" \n",
    "org_key = \"\" \n",
    "\n",
    "apikey_path = \"../apikeys/api_openai_llamaindex.key\"\n",
    "orgKey_path = \"../apikeys/api_openai_org.key\"\n",
    "\n",
    "with open(apikey_path, 'r') as file:\n",
    "    api_key = file.read().strip()\n",
    "\n",
    "with open(orgKey_path, 'r') as file:\n",
    "    org_key = file.read().strip()\n",
    "    \n",
    "openai_client = OpenAI(api_key=api_key, organization=org_key) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# gpt-3.5-turbo-1106\n",
    "# gpt-4-1106-preview\n",
    "\n",
    "def GPT(system_prompt, user_prompt):\n",
    "    result = \"\" \n",
    "    prompt_tokens = 0 \n",
    "    completion_tokens = 0\n",
    "    total_tokens = 0\n",
    "\n",
    "    try:\n",
    "        response = openai_client.chat.completions.create(\n",
    "            messages=[{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": user_prompt}],\n",
    "            temperature=0,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=None,\n",
    "            max_tokens=1500,\n",
    "            model=\"gpt-4-1106-preview\",\n",
    "        )     \n",
    "        #result =  response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        result = response.choices[0].message.content \n",
    "        prompt_tokens = response.usage.prompt_tokens\n",
    "        completion_tokens = response.usage.completion_tokens\n",
    "        total_tokens = response.usage.total_tokens\n",
    "\n",
    "        return result, prompt_tokens, completion_tokens, total_tokens\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred on GPT: {e}\")\n",
    "        return None, 0, 0, 0\n",
    "    \n",
    "system_prompt = \"You are a very helpful assistant. You will help me summarize a meeting transcript.\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_path = 'meeting3_transcription.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file and read its content into a variable\n",
    "with open(transcript_path, 'r', encoding='utf-8') as file:\n",
    "    transcript = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_prompt = f\"\"\"Meeting:\n",
    "{transcript}\n",
    "\n",
    "Objective: Generate increasingly concise, entity-dense summaries of the meeting and action items.\n",
    "\n",
    "Process: Repeat the following steps five times:\n",
    "\n",
    "Step 1: Identify 1-3 informative entities (separated by semicolons) missing from the previously generated summary.\n",
    "Step 2: Write a new, denser summary of the same length that covers all entities and details from the previous summary, including the missing entities.\n",
    "\n",
    "Missing Entities Criteria:\n",
    "Relevant: Pertinent to the main discussion.\n",
    "Specific: Descriptive yet concise (5 words or fewer).\n",
    "Novel: Not present in the previous summary.\n",
    "Faithful: Reflects information discussed during the meeting.\n",
    "Anywhere: Can appear anywhere in the new summary.\n",
    "\n",
    "Guidelines:\n",
    "The initial summary should be long (4-5 sentences, ~80 words) but highly nonspecific, using verbose language and fillers (e.g., “the meeting covered”) to reach the word count.\n",
    "\n",
    "Optimize each word: Rewrite the previous summary to improve flow and create space for additional entities.\n",
    "\n",
    "Condense by fusing, compressing, and removing uninformative phrases (e.g., “the discussion focused on”).\n",
    "\n",
    "The summaries should become highly dense and self-contained, easily understood without referring to the meeting notes.\n",
    "\n",
    "Missing entities can be inserted anywhere in the new summary.\n",
    "\n",
    "Never drop entities from the previous summary; if space is limited, add fewer new entities.\n",
    "\n",
    "By the end provide entities with sentence description as Meeting summary.\n",
    "\"\"\"\n",
    "\n",
    "summary, prompt_tokens, completion_tokens, total_tokens = GPT(system_prompt, summary_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tasks_prompt = f\"\"\"From the following TRANSCRIPT can you please create a detailed list of tasks assigned to participants.  Please make sure to start each task with the person assigned to it.\n",
    "\n",
    "TRANSCRIPT:\n",
    "{transcript}\n",
    "\n",
    "TASKS:\n",
    "\"\"\" \n",
    "\n",
    "tasks, prompt_tokens, completion_tokens, total_tokens = GPT(system_prompt, tasks_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "priorities_prompt = f\"\"\"From the following TRANSCRIPT please identify the most prioritary to-do actions and who is assigned to each one of them. Please assign a priority tag like HIGH, MEDIUM, LOW and order the list according to these priorities.\n",
    "\n",
    "In the list please format it like so: <priority> - <person in charge>: <description> \n",
    "\n",
    "For example:\n",
    "\n",
    "HIGH - Cindy: Connect with GTM teams to ensure support for corporate events.\n",
    "\n",
    "TRANSCRIPT:\n",
    "{transcript}\n",
    "\n",
    "PRIORITIES:\n",
    "\"\"\" \n",
    "\n",
    "priorities, prompt_tokens, completion_tokens, total_tokens = GPT(system_prompt, priorities_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(priorities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
